{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "788d292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # its VERY IMPORTANT this says cuda\n",
    "print(DEVICE)\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import math\n",
    "import os\n",
    "from torchinfo import summary\n",
    "import json\n",
    "from itertools import product\n",
    "import time\n",
    "import re\n",
    "import shutil\n",
    "import soundfile as sf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcceb62",
   "metadata": {},
   "source": [
    "# Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eab7b17",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "052de221",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset that lazily loads WAV files from\n",
    "    x directory and y directory from a list\n",
    "    with the relative paths of the files.\n",
    "    \n",
    "    Args:\n",
    "        x_files, y_files\n",
    "    \n",
    "    Returns:\n",
    "        waveform (torch.Tensor): Tensor containing the waveform.\n",
    "        filename (str): Name of the file without the extension.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, x_files, y_files):\n",
    "        assert len(x_files) == len(y_files), \"Inputs and targets must match\"\n",
    "        self.x_files = x_files\n",
    "        self.y_files = y_files\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x_files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        wav_path = self.x_files[index]\n",
    "        waveform_x, _ = torchaudio.load(wav_path)\n",
    "        filename_x = wav_path.stem\n",
    "\n",
    "        wav_path = self.y_files[index]\n",
    "        waveform_y, _ = torchaudio.load(wav_path)\n",
    "        filename_y = wav_path.stem\n",
    "\n",
    "        return waveform_x, filename_x, waveform_y, filename_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8398dc9d",
   "metadata": {},
   "source": [
    "## Dataset analysis\n",
    "| Training Dataset (s) | Test Dataset (s) | Range | Noise |\n",
    "| - | - | - | - |\n",
    "| Max: 15.11 <br> Min: 1.09 <br> Avg: 2.92 | Max: 9.76 <br> Min: 1.23 <br> Avg: 2.51 | Waveforms normalized to [-1,1] | Noise is real, not randomly generated|\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "If padding was applied to 20 s (20*48000=960000), tensors would be too big, need to downsample to 16kHz, no need to normalize data, the model must be able to handle this type of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4798550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dir = \"../data/clean_trainset_28spk_wav\"\n",
    "# dataset = WavDataset(dataset_dir)\n",
    "# loader = DataLoader(dataset, batch_size=1, num_workers=1,shuffle=False)\n",
    "\n",
    "# def analysis(x):\n",
    "#     return len(x[0].squeeze())/48000\n",
    "\n",
    "# lengths = []\n",
    "# for batch in loader:\n",
    "#     lengths.append(analysis(batch))\n",
    "\n",
    "# print('Training Dataset')\n",
    "# print('Max length',max(lengths))\n",
    "# print('Min length',min(lengths))\n",
    "# print('Avg length',sum(lengths)/len(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "575aae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dir = \"../data/clean_testset_wav\"\n",
    "# dataset = WavDataset(dataset_dir)\n",
    "# loader = DataLoader(dataset, batch_size=1, num_workers=1,shuffle=False)\n",
    "\n",
    "# lengths = []\n",
    "# for batch in loader:\n",
    "#     lengths.append(analysis(batch))\n",
    "    \n",
    "# print('Test Dataset')\n",
    "# print('Max length',max(lengths))\n",
    "# print('Min length',min(lengths))\n",
    "# print('Avg length',sum(lengths)/len(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b376ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_dataset_dir = \"../data/clean_testset_wav\"\n",
    "# clean_dataset = WavDataset(clean_dataset_dir)\n",
    "# clean_wav = clean_dataset[0][0].squeeze()\n",
    "\n",
    "# noisy_dataset_dir = \"../data/noisy_testset_wav\"\n",
    "# noisy_dataset = WavDataset(noisy_dataset_dir)\n",
    "# noisy_wav = noisy_dataset[0][0].squeeze()\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "# ax[0].plot(clean_wav)\n",
    "# ax[0].set_title(\"Clean Audio\")\n",
    "\n",
    "# ax[1].plot(noisy_wav)\n",
    "# ax[1].set_title(\"Noisy Audio\")\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# display(Audio(clean_wav, rate=48000))\n",
    "# display(Audio(noisy_wav, rate=48000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20b0499",
   "metadata": {},
   "source": [
    "## Train/Val/Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a625a9bd",
   "metadata": {},
   "source": [
    "#### Resampling by rate and filter by duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "460d87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_ROOT_48K = Path(\"../data\")          # original 48 kHz root\n",
    "DST_ROOT_16K = Path(\"../data_16k\")      # downsampled root\n",
    "FREQ = 16000                            # target sample rate\n",
    "SECONDS = 3.2                           # max duration to keep (seconds)\n",
    "\n",
    "FOLDERS = [\n",
    "    \"clean_trainset_28spk_wav\",\n",
    "    \"noisy_trainset_28spk_wav\",\n",
    "    \"clean_testset_wav\",\n",
    "    \"noisy_testset_wav\",\n",
    "]\n",
    "\n",
    "\n",
    "# ---------- STEP 1: DOWNSAMPLING ----------\n",
    "def resample_folder_by_rate(src_dir: Path, dst_dir: Path, target_sr: int = FREQ):\n",
    "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    example_files = list(src_dir.glob(\"*.wav\"))\n",
    "    if not example_files:\n",
    "        print(f\"[WARN] No wav files in {src_dir}\")\n",
    "        return\n",
    "\n",
    "    _, orig_sr = torchaudio.load(example_files[0])\n",
    "    if orig_sr == target_sr:\n",
    "        print(f\"[INFO] {src_dir} already at {orig_sr} Hz, copying as-is.\")\n",
    "        resampler = None\n",
    "    else:\n",
    "        print(f\"[INFO] Resampling {src_dir} from {orig_sr} Hz to {target_sr} Hz\")\n",
    "        resampler = torchaudio.transforms.Resample(orig_sr, target_sr)\n",
    "\n",
    "    for wav_path in sorted(src_dir.glob(\"*.wav\")):\n",
    "        dst_path = dst_dir / wav_path.name\n",
    "\n",
    "        if dst_path.exists():\n",
    "            continue  # skip already processed\n",
    "\n",
    "        waveform, sr = torchaudio.load(wav_path)\n",
    "        if resampler is not None:\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        torchaudio.save(dst_path, waveform, target_sr)\n",
    "\n",
    "    print(f\"[DONE] {src_dir} -> {dst_dir}\")\n",
    "\n",
    "\n",
    "def downsample_all():\n",
    "    for folder in FOLDERS:\n",
    "        src_dir = SRC_ROOT_48K / folder\n",
    "        dst_dir = DST_ROOT_16K / folder\n",
    "        if not src_dir.exists():\n",
    "            print(f\"[SKIP] Source directory not found: {src_dir}\")\n",
    "            continue\n",
    "        resample_folder_by_rate(src_dir, dst_dir)\n",
    "\n",
    "\n",
    "# ---------- STEP 2: FILTER BY DURATION (ON 16 kHz DATA) ----------\n",
    "def filter_by_duration(src_dir: Path, max_duration_sec: float, target_sr: int = FREQ):\n",
    "    \"\"\"\n",
    "    Returns list of wav files in src_dir with duration <= max_duration_sec\n",
    "    and sample rate == target_sr.\n",
    "    \"\"\"\n",
    "    wav_files = list(src_dir.glob(\"*.wav\"))\n",
    "    if not wav_files:\n",
    "        print(f\"[WARN] No wav files in {src_dir}\")\n",
    "        return []\n",
    "\n",
    "    kept_files = []\n",
    "\n",
    "    for wav_path in sorted(wav_files):\n",
    "        try:\n",
    "            info = sf.info(wav_path)\n",
    "            duration = info.duration\n",
    "\n",
    "            if info.samplerate != target_sr:\n",
    "                print(f\"[SKIP] {wav_path.name}: wrong SR {info.samplerate}, expected {target_sr}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not read {wav_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if duration <= max_duration_sec:\n",
    "            kept_files.append(wav_path)\n",
    "\n",
    "    print(f\"[DONE] {src_dir} | Kept {len(kept_files)}/{len(wav_files)} files\")\n",
    "    return kept_files\n",
    "\n",
    "\n",
    "def build_kept_files_dict():\n",
    "    \"\"\"\n",
    "    Runs duration filtering on the already-downsampled data_16k and\n",
    "    returns a dict: {folder_name: [Path(...), ...], ...}\n",
    "    \"\"\"\n",
    "    kept_files_by_folder = {}\n",
    "    total_kept = 0\n",
    "    total_files = 0\n",
    "\n",
    "    for folder in FOLDERS:\n",
    "        src_dir = DST_ROOT_16K / folder\n",
    "\n",
    "        if not src_dir.exists():\n",
    "            print(f\"[SKIP] Source directory not found: {src_dir}\")\n",
    "            continue\n",
    "\n",
    "        kept = filter_by_duration(src_dir, SECONDS, FREQ)\n",
    "        kept_files_by_folder[folder] = kept\n",
    "        total_kept += len(kept)\n",
    "        total_files += len(list(src_dir.glob(\"*.wav\")))\n",
    "\n",
    "    print(\"\\n=== SUMMARY ===\")\n",
    "    print(f\"Total kept: {total_kept}/{total_files} files\")\n",
    "\n",
    "    return kept_files_by_folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf334fd",
   "metadata": {},
   "source": [
    "#### Dataloader: collate function, splitting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e148f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # batch is a list of tuples:\n",
    "    # (waveform_x, filename_x, waveform_y, filename_y)\n",
    "    waveform_x_list, filename_x_list, waveform_y_list, filename_y_list = zip(*batch)\n",
    "\n",
    "    # Assume torchaudio.load → waveform: [channels, samples]\n",
    "    # Convert to [samples] (mono) by squeezing channel dim\n",
    "    xs = [w.squeeze(0) for w in waveform_x_list]\n",
    "    ys = [w.squeeze(0) for w in waveform_y_list]\n",
    "\n",
    "    batch_size = len(xs)\n",
    "    target_len = int(SECONDS * FREQ)\n",
    "\n",
    "    # Allocate padded tensors [batch, target_len]\n",
    "    x_padded = torch.zeros(batch_size, target_len)\n",
    "    y_padded = torch.zeros(batch_size, target_len)\n",
    "\n",
    "    # Truncate or pad each waveform\n",
    "    for i, (x, y) in enumerate(zip(xs, ys)):\n",
    "        x_len = min(x.shape[0], target_len)\n",
    "        y_len = min(y.shape[0], target_len)\n",
    "\n",
    "        x_padded[i, :x_len] = x[:x_len]\n",
    "        y_padded[i, :y_len] = y[:y_len]\n",
    "\n",
    "    # Add channel dimension: [batch, 1, target_len]\n",
    "    x_padded = x_padded.unsqueeze(1)\n",
    "    y_padded = y_padded.unsqueeze(1)\n",
    "\n",
    "    return x_padded, y_padded, list(filename_x_list), list(filename_y_list)\n",
    "\n",
    "def create_split(\n",
    "    batch_size,\n",
    "    num_workers,\n",
    "    sample_size,\n",
    "    noisy_train_files,\n",
    "    clean_train_files,\n",
    "    noisy_test_files,\n",
    "    clean_test_files,\n",
    "    ratio=0.9,\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create train/val/test dataloaders from paired audio files.\n",
    "    \n",
    "    Args:\n",
    "        batch_size: Batch size for DataLoader\n",
    "        num_workers: Number of workers for DataLoader\n",
    "        sample_size: Limit number of training samples (None = use all)\n",
    "        noisy_train_files: List of noisy train file paths\n",
    "        clean_train_files: List of clean train file paths\n",
    "        noisy_test_files: List of noisy test file paths\n",
    "        clean_test_files: List of clean test file paths\n",
    "        ratio: Train/val split ratio (default 0.9)\n",
    "        seed: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        train_loader, val_loader, test_loader\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Limit sample size if specified\n",
    "    if sample_size is not None:\n",
    "        actual_size = min(sample_size, len(noisy_train_files))\n",
    "        noisy_train_files = noisy_train_files[:actual_size]\n",
    "        clean_train_files = clean_train_files[:actual_size]\n",
    "    \n",
    "    # Train/val split\n",
    "    train_size = int(ratio * len(noisy_train_files))\n",
    "    indices = torch.randperm(len(noisy_train_files))\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:]\n",
    "    \n",
    "    # Split file lists (keeping pairs matched)\n",
    "    x_train_files = [noisy_train_files[i] for i in train_indices]\n",
    "    y_train_files = [clean_train_files[i] for i in train_indices]\n",
    "    x_val_files = [noisy_train_files[i] for i in val_indices]\n",
    "    y_val_files = [clean_train_files[i] for i in val_indices]\n",
    "    \n",
    "    # Create paired datasets\n",
    "    train_dataset = WavDataset(x_train_files, y_train_files)\n",
    "    val_dataset = WavDataset(x_val_files, y_val_files)\n",
    "    test_dataset = WavDataset(noisy_test_files, clean_test_files)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521bc70d",
   "metadata": {},
   "source": [
    "# Denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b0adb",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8ac1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wave_UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements Wave-U-Net, meaning it employs 1D convolutions in a \n",
    "    encode-decode structure that takes raw audio and denoises it.\n",
    "    It uses LeakyReLU as the activation function except \n",
    "    in the last layer which is tanh.\n",
    "\n",
    "    To reduce noise artifacts, no transpose convolutions are used,\n",
    "    and the convolutions are set to 0 padding. To compensate for\n",
    "    this, the waveforms are padded with 0s. \n",
    "\n",
    "    Regarding how the time domain is shrunk and expanded, decimate\n",
    "    is used for downsampling and a custom interpolation function is \n",
    "    usd for upsampling. Notably, it doesn't extrapolate, meaning\n",
    "    the output is actually 2n-1 instead of the usual 2n.\n",
    "\n",
    "    DISCLAIMER:\n",
    "    A short waveform paired with a high depth will NOT work. Beware.\n",
    "    \"\"\"\n",
    "    def __init__(self, depth=12, base_filters=24): # add transformation function\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.padding = self.compute_padding()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoders = nn.ModuleList()\n",
    "        in_ch = 1 \n",
    "        for i in range(depth): # 0 -> depth-1\n",
    "            out_ch = base_filters * (i + 1)\n",
    "            self.encoders.append(self.EncoderBlock(in_ch, out_ch))\n",
    "            in_ch = out_ch\n",
    "        \n",
    "        # Mid convolution, which has no decimation\n",
    "        out_ch = in_ch+base_filters\n",
    "        self.mid_conv = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, out_ch, kernel_size = 15, padding=0),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        in_ch = out_ch\n",
    "\n",
    "        # Decoder\n",
    "        self.decoders = nn.ModuleList()\n",
    "        for i in range(depth-1, 0, -1): # depth-1 -> 1 for the staggered interpolation\n",
    "            out_ch = base_filters * (i + 1)\n",
    "            self.decoders.append(self.DecoderBlock(in_ch, out_ch, out_ch))\n",
    "            in_ch = out_ch\n",
    "\n",
    "        # staggered interpolation, fix this\n",
    "        self.StaggeredBlock = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2,mode='linear',align_corners=True),\n",
    "            nn.Conv1d(in_ch+base_filters, base_filters, kernel_size = 15, padding=0),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.final_conv = nn.Conv1d(base_filters+1, 1, kernel_size=1, padding=0) # finale, kernel size 1 conv, from base_filters+1 -> 1\n",
    "         \n",
    "    def forward(self, x):\n",
    "        original = x # for the finale\n",
    "        x = F.pad(x, (self.padding, self.padding), mode='constant', value=0) \n",
    "\n",
    "        # DOWNSAMPLER\n",
    "        skips = []\n",
    "        for enc in self.encoders:\n",
    "            x, skip = enc(x)\n",
    "            skips.append(skip)\n",
    "\n",
    "        x = self.mid_conv(x) # mid conv\n",
    "\n",
    "        # UPSAMPLER\n",
    "        for dec in self.decoders:\n",
    "            skip = self.center_crop(skips.pop(),(x.shape[-1]*2)-1)\n",
    "            x = dec(x, skip)\n",
    "\n",
    "        # Staggered upsampler\n",
    "        # add center crop\n",
    "        skip = self.center_crop(skips.pop(), x.shape[-1])\n",
    "        x = torch.cat([skip, x], dim=1)\n",
    "        x = self.StaggeredBlock(x)\n",
    "        \n",
    "        x = self.center_crop(x, original.shape[-1])\n",
    "        x = torch.cat([x, original], dim=1)\n",
    "        x = self.final_conv(x) # finale + tanh activation function\n",
    "        return x\n",
    "    \n",
    "    class EncoderBlock(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super().__init__()\n",
    "            self.conv = nn.Conv1d(in_channels, out_channels, \n",
    "                                  kernel_size=15, padding=0) # padding_mode='zeros'\n",
    "            self.leaky_relu = nn.LeakyReLU()\n",
    "            self.decimate = Wave_UNet.Decimate2()\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv(x)\n",
    "            x = self.leaky_relu(x)\n",
    "            skip = x\n",
    "            x = self.decimate(x)\n",
    "            return x, skip\n",
    "        \n",
    "    class DecoderBlock(nn.Module):\n",
    "        def __init__(self, in_channels, skip_channels, out_channels):\n",
    "            super().__init__()\n",
    "            self.upsample = Wave_UNet.Interpolate2()\n",
    "            self.conv = nn.Conv1d(in_channels+skip_channels, out_channels, \n",
    "                                    kernel_size=5, padding=0) \n",
    "            self.leaky_relu = nn.LeakyReLU()\n",
    "            \n",
    "        def forward(self, x, skip):\n",
    "            x = self.upsample(x)\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "            x = self.conv(x)\n",
    "            x = self.leaky_relu(x)\n",
    "            return x\n",
    "    \n",
    "    class Decimate2(nn.Module): # cuts size in half by skipping every other step\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "        def forward(self, x):\n",
    "            return x[..., ::2]\n",
    "    \n",
    "    class Interpolate2(nn.Module): # it differs to Upsample by having a 2n-1 output size\n",
    "        def __init__(self,):\n",
    "            super().__init__()\n",
    "        def forward(self, x):\n",
    "            # remember, input is a batch\n",
    "            T = x.shape[-1]\n",
    "            out_shape = list(x.shape)\n",
    "            out_shape[-1] = 2 * T - 1\n",
    "            # calculate interpolation\n",
    "            output = torch.empty(out_shape, device=x.device, dtype=x.dtype) \n",
    "            output[...,::2] = x\n",
    "            output[...,1::2] = 0.5 * (x[..., :-1] + x[..., 1:])\n",
    "            return output\n",
    "        \n",
    "    def compute_padding(self):\n",
    "        # Makes a estimate of how much padding is needed on each side \n",
    "        # of each tendor to compensate for padding=0. \n",
    "        # Takes the reverse route of the Wave U-Net\n",
    "        padding = 0 # initialize\n",
    "\n",
    "        # UPSAMPLER\n",
    "        # staggered interpolation\n",
    "        padding += 4 # conv\n",
    "        padding = math.ceil(padding/2) # interpolation\n",
    "\n",
    "        for _ in range(self.depth-1):\n",
    "            padding += 4 # conv\n",
    "            padding = math.ceil((padding+1)/2 ) # interpolation\n",
    "\n",
    "        padding += 14 # mid conv\n",
    "\n",
    "        # DOWNSAMPLER\n",
    "        for _ in range(self.depth):\n",
    "            padding = 2*padding # decimate\n",
    "            padding += 14 # conv\n",
    "        \n",
    "        return int(padding/2) # F.pad doesnt take float\n",
    "    \n",
    "    def center_crop(self, x, target_len):\n",
    "        # x is (B, C, T), target_len is int\n",
    "        current_len = x.shape[-1]\n",
    "        diff = current_len - target_len\n",
    "        if diff == 0: return x\n",
    "        if diff < 0: raise ValueError(\"Target bigger than input!\")\n",
    "        start = diff // 2\n",
    "        end = start + target_len\n",
    "        return x[..., start:end]\n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9658a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, dilation=1):\n",
    "        super().__init__()\n",
    "        self.conv1x1_in = nn.Conv2d(in_ch, out_ch, kernel_size=1, padding=0)\n",
    "        self.conv3x3 = nn.Conv2d(\n",
    "            out_ch, out_ch, kernel_size=3,\n",
    "            padding=dilation, dilation=dilation\n",
    "        )\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "        self.conv1x1_out = nn.Conv2d(out_ch, out_ch, kernel_size=1, padding=0)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1x1_in(x)\n",
    "        x = self.conv3x3(x)\n",
    "        x = self.prelu(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.conv1x1_out(x)\n",
    "        skip = x\n",
    "        x = self.pool(x)\n",
    "        return x, skip\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # upconv will be set per block when UNet is built\n",
    "        self.upconv = None\n",
    "        self.conv1 = None\n",
    "        self.bn1 = None\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = None\n",
    "        self.bn2 = None\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def center_crop(self, x, th, tw):\n",
    "        h, w = x.shape[-2:]\n",
    "        dh, dw = h - th, w - tw\n",
    "        if dh == 0 and dw == 0:\n",
    "            return x\n",
    "        sh, sw = dh // 2, dw // 2\n",
    "        return x[..., sh:sh+th, sw:sw+tw]\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.upconv(x)\n",
    "\n",
    "        if x.shape[-2:] != skip.shape[-2:]:\n",
    "            skip = self.center_crop(skip, x.shape[-2], x.shape[-1])\n",
    "\n",
    "        x = torch.cat([x, skip], dim=1)             # (B, C_cat, H, W)\n",
    "        C_cat = x.shape[1]\n",
    "\n",
    "        # lazily build convs with correct channel sizes\n",
    "        if self.conv1 is None:\n",
    "            self.conv1 = nn.Conv2d(C_cat, C_cat, kernel_size=3, padding=1).to(x.device)\n",
    "            self.bn1 = nn.BatchNorm2d(C_cat).to(x.device)\n",
    "        if self.conv2 is None:\n",
    "            out_ch = skip.shape[1]\n",
    "            self.conv2 = nn.Conv2d(C_cat, out_ch, kernel_size=3, padding=1).to(x.device)\n",
    "            self.bn2 = nn.BatchNorm2d(out_ch).to(x.device)\n",
    "\n",
    "        x = self.conv1(x); x = self.relu1(x); x = self.bn1(x)\n",
    "        x = self.conv2(x); x = self.relu2(x); x = self.bn2(x)\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, encoder_channels=None,\n",
    "                 forward_transform=None,\n",
    "                 inverse_transform=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # default channels if none provided\n",
    "        if encoder_channels is None:\n",
    "            encoder_channels = [32, 64, 128, 256, 256, 512, 512]\n",
    "        self.channels = encoder_channels\n",
    "\n",
    "        # pluggable transforms (modules)\n",
    "        assert forward_transform is not None\n",
    "        assert inverse_transform is not None\n",
    "        self.forward_transform = forward_transform\n",
    "        self.inverse_transform = inverse_transform\n",
    "\n",
    "        # Encoder\n",
    "        self.encoders = nn.ModuleList()\n",
    "        in_ch = 1\n",
    "        for ch in self.channels:\n",
    "            self.encoders.append(EncoderBlock(in_ch, ch))\n",
    "            in_ch = ch\n",
    "\n",
    "        # Decoder (one per encoder, using all skips)\n",
    "        self.decoders = nn.ModuleList()\n",
    "        dec_in_ch = self.channels[-1]\n",
    "        skip_chs = self.channels\n",
    "        for skip_ch in reversed(skip_chs):\n",
    "            block = DecoderBlock()\n",
    "            block.upconv = nn.ConvTranspose2d(dec_in_ch, dec_in_ch, kernel_size=2, stride=2)\n",
    "            self.decoders.append(block)\n",
    "            dec_in_ch = skip_ch\n",
    "\n",
    "        self.final_conv = nn.Conv2d(dec_in_ch, 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, noisy_waveform):\n",
    "        # 1) generic forward transform: waveform -> aux, phase\n",
    "        aux, phase = self.forward_transform(noisy_waveform)   # (B,1,F,T), phase\n",
    "\n",
    "        B, C, F_orig, T_orig = aux.shape\n",
    "\n",
    "        # 2) crop to multiple of 2^N (N=len(channels))\n",
    "        div = 2 ** len(self.channels)\n",
    "        F_crop = (F_orig // div) * div\n",
    "        T_crop = (T_orig // div) * div\n",
    "        aux_c = aux[:, :, :F_crop, :T_crop]\n",
    "\n",
    "        # 3) U-Net\n",
    "        x = aux_c\n",
    "        skips = []\n",
    "        for enc in self.encoders:\n",
    "            x, skip = enc(x)\n",
    "            skips.append(skip)\n",
    "\n",
    "        for dec in self.decoders:\n",
    "            x = dec(x, skips.pop())\n",
    "\n",
    "        enh_aux_c = self.final_conv(x)    # (B,1,F_crop,T_crop)\n",
    "\n",
    "        # 4) resize back\n",
    "        enh_aux = F.interpolate(\n",
    "            enh_aux_c,\n",
    "            size=(F_orig, T_orig),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        )\n",
    "\n",
    "        # 5) inverse transform\n",
    "        enhanced = self.inverse_transform(enh_aux, phase)\n",
    "        return enhanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f662c",
   "metadata": {},
   "source": [
    "#### U-Net modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0905452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT \n",
    "class STFTLogPower(nn.Module):\n",
    "    def __init__(self, n_fft=1024, hop_length=160, win_length=400, eps=1e-12):\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.win_length = win_length\n",
    "        self.eps = eps\n",
    "        window = torch.hann_window(win_length)\n",
    "        self.register_buffer(\"window\", window)\n",
    "\n",
    "    def forward(self, waveform):\n",
    "        # waveform: (B,1,T)\n",
    "        B, C, T = waveform.shape\n",
    "        assert C == 1\n",
    "        spec = torch.stft(\n",
    "            waveform.squeeze(1),\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            win_length=self.win_length,\n",
    "            window=self.window,\n",
    "            center=True,\n",
    "            return_complex=True,\n",
    "        )\n",
    "        mag = spec.abs()\n",
    "        aux = (mag ** 2 + self.eps).log()      # generic \"aux\" rep\n",
    "        return aux.unsqueeze(1), spec          # (B,1,F,T), phase/spec\n",
    "\n",
    "class ISTFTFromLogPower(nn.Module):\n",
    "    def __init__(self, n_fft=1024, hop_length=160, win_length=400):\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.win_length = win_length\n",
    "        window = torch.hann_window(win_length)\n",
    "        self.register_buffer(\"window\", window)\n",
    "\n",
    "    def forward(self, aux, phase):\n",
    "        # aux: log-power-like (B,1,F,T)\n",
    "        mag = (aux.exp()).sqrt().squeeze(1)    # (B,F,T)\n",
    "        complex_spec = mag * phase / (phase.abs() + 1e-12)\n",
    "        wav = torch.istft(\n",
    "            complex_spec,\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            win_length=self.win_length,\n",
    "            window=self.window,\n",
    "            center=True,\n",
    "        )\n",
    "        return wav.unsqueeze(1)                # (B,1,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ffcac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-mel\n",
    "class MelLogMag(nn.Module):\n",
    "    def __init__(self, sample_rate=16000,\n",
    "                 n_fft=1024, hop_length=160, win_length=400,\n",
    "                 n_mels=256, eps=1e-12):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.win_length = win_length\n",
    "        self.window = torch.hann_window(win_length)\n",
    "        self.mel = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sample_rate,\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            win_length=win_length,\n",
    "            n_mels=n_mels,\n",
    "            power=2.0,\n",
    "        )\n",
    "\n",
    "    def forward(self, waveform):\n",
    "        # waveform: (B,1,T)\n",
    "        B, C, T = waveform.shape\n",
    "        assert C == 1\n",
    "        # 1) STFT for phase\n",
    "        spec = torch.stft(\n",
    "            waveform.squeeze(1),\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            win_length=self.win_length,\n",
    "            window=self.window.to(waveform.device),\n",
    "            center=True,\n",
    "            return_complex=True,\n",
    "        )                           # (B, F, T_spec)\n",
    "\n",
    "        # 2) Mel on waveform, not on spec\n",
    "        mel = self.mel(waveform.squeeze(1))   # (B, n_mels, T_mel)\n",
    "        aux = (mel + self.eps).log().unsqueeze(1)\n",
    "        return aux, spec\n",
    "         \n",
    "    \n",
    "class InvMelLogMag(nn.Module):\n",
    "    def __init__(self, sample_rate=16000,\n",
    "                 n_fft=1024, hop_length=160, win_length=400,\n",
    "                 n_mels=256):\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.win_length = win_length\n",
    "        self.window = torch.hann_window(win_length)\n",
    "        self.mel_inv = torchaudio.transforms.InverseMelScale(\n",
    "            n_stft=n_fft // 2 + 1,\n",
    "            n_mels=n_mels,\n",
    "            sample_rate=sample_rate,\n",
    "        )\n",
    "\n",
    "    def forward(self, aux, phase):\n",
    "        # aux: (B,1,M,Tm)\n",
    "        mel = (aux.squeeze(1).exp())          # (B,M,Tm)\n",
    "        mag2 = self.mel_inv(mel)              # (B,F,T)\n",
    "        mag = mag2.clamp(min=0).sqrt()\n",
    "        complex_spec = mag * phase / (phase.abs() + 1e-12)\n",
    "        wav = torch.istft(\n",
    "            complex_spec,\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            win_length=self.win_length,\n",
    "            window=self.window.to(phase.device),\n",
    "            center=True,\n",
    "        )\n",
    "        return wav.unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c78caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC‑like cepstrogram\n",
    "class Cepstrogram(nn.Module):\n",
    "    def __init__(self, sample_rate=16000,\n",
    "                 n_fft=1024, hop_length=160, win_length=400,\n",
    "                 n_mels=128, n_ceps=64, eps=1e-12):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.stft = STFTLogPower(n_fft=n_fft,\n",
    "                                 hop_length=hop_length,\n",
    "                                 win_length=win_length,\n",
    "                                 eps=eps)\n",
    "        self.mel_fb = torchaudio.transforms.MelScale(\n",
    "            n_mels=n_mels,\n",
    "            sample_rate=sample_rate,\n",
    "            n_stft=n_fft // 2 + 1,\n",
    "        )\n",
    "        self.n_ceps = n_ceps\n",
    "\n",
    "    def forward(self, waveform):\n",
    "        _, spec = self.stft(waveform)          # spec: (B,F,T)\n",
    "        mag = spec.abs()\n",
    "        mel = self.mel_fb(mag)                 # (B,M,T)\n",
    "        log_mel = (mel + self.eps).log()\n",
    "        # DCT-II along mel axis\n",
    "        cep = torch.real(torch.fft.dct(log_mel, type=2, dim=1, norm='ortho'))\n",
    "        cep = cep[:, :self.n_ceps, :]          # (B, n_ceps, T)\n",
    "        return cep.unsqueeze(1), spec\n",
    "\n",
    "class InvCepstrogram(nn.Module):\n",
    "    def __init__(self, sample_rate=16000,\n",
    "                 n_fft=1024, hop_length=160, win_length=400,\n",
    "                 n_mels=128, n_ceps=64):\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.win_length = win_length\n",
    "        window = torch.hann_window(win_length)\n",
    "        self.register_buffer(\"window\", window)\n",
    "\n",
    "        fb = torchaudio.transforms.MelScale(\n",
    "            n_mels=n_mels,\n",
    "            sample_rate=sample_rate,\n",
    "            n_stft=n_fft // 2 + 1,\n",
    "        ).fb\n",
    "        self.register_buffer(\"mel_inv\", torch.pinverse(fb))\n",
    "        self.n_mels = n_mels\n",
    "        self.n_ceps = n_ceps\n",
    "\n",
    "    def forward(self, aux, phase):\n",
    "        mel = (aux.squeeze(1).exp()).sqrt()      # (B, M, T)\n",
    "        mel = mel.permute(0, 2, 1)               # (B, T, M)\n",
    "        mag = torch.matmul(mel, self.mel_inv.T)  # (B, T, n_stft)\n",
    "        mag = mag.permute(0, 2, 1)               # (B, n_stft, T)\n",
    "\n",
    "        complex_spec = mag * phase / (phase.abs() + 1e-12)\n",
    "        wav = torch.istft(\n",
    "            complex_spec,\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            win_length=self.win_length,\n",
    "            window=self.window,\n",
    "            center=True,\n",
    "        )\n",
    "        return wav.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4524a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log‑CQT magnitude\n",
    "class CQTLogMag(nn.Module):\n",
    "    def __init__(self, sample_rate=16000,\n",
    "                 hop_length=160,\n",
    "                 fmin=32.7, bins_per_octave=24, n_bins=256,\n",
    "                 eps=1e-12):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.cqt = torchaudio.transforms.CQT(\n",
    "            sample_rate=sample_rate,\n",
    "            hop_length=hop_length,\n",
    "            fmin=fmin,\n",
    "            n_bins=n_bins,\n",
    "            bins_per_octave=bins_per_octave,\n",
    "        )\n",
    "\n",
    "    def forward(self, waveform):\n",
    "        # waveform: (B,1,T)\n",
    "        B, C, T = waveform.shape\n",
    "        assert C == 1\n",
    "        cqt = self.cqt(waveform.squeeze(1))    # (B, n_bins, T) complex\n",
    "        mag = cqt.abs()\n",
    "        aux = (mag ** 2 + self.eps).log()\n",
    "        return aux.unsqueeze(1), cqt\n",
    "\n",
    "class InvCQTLogMag(nn.Module):\n",
    "    def __init__(self, sample_rate=16000,\n",
    "                 hop_length=160,\n",
    "                 fmin=32.7, bins_per_octave=24, n_bins=256):\n",
    "        super().__init__()\n",
    "        self.inv_cqt = torchaudio.transforms.InverseCQT(\n",
    "            sample_rate=sample_rate,\n",
    "            hop_length=hop_length,\n",
    "            fmin=fmin,\n",
    "            n_bins=n_bins,\n",
    "            bins_per_octave=bins_per_octave,\n",
    "        )\n",
    "\n",
    "    def forward(self, aux, phase):\n",
    "        mag = (aux.squeeze(1).exp()).sqrt()    # (B, n_bins, T)\n",
    "        complex_cqt = mag * phase / (phase.abs() + 1e-12)\n",
    "        wav = self.inv_cqt(complex_cqt)        # (B, T)\n",
    "        return wav.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746cd77",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19547ff",
   "metadata": {},
   "source": [
    "#### Hyperparameters, Split creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "018cd7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CONFIG ----------\n",
    "MODEL_DIR = Path(\"../model\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "HIST_DIR = Path(\"../history\")\n",
    "HIST_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Split parameters\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "sample_size = 64 # None = Use all files\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 5\n",
    "print_every = 1\n",
    "Loss = nn.L1Loss\n",
    "LR = 1e-4\n",
    "PATIENCE = 20 # epochs with no val improvement\n",
    "min_delta = 0  # min difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bbb747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] ../data_16k/clean_trainset_28spk_wav | Kept 8181/11572 files\n",
      "[DONE] ../data_16k/noisy_trainset_28spk_wav | Kept 8181/11572 files\n",
      "[DONE] ../data_16k/clean_testset_wav | Kept 689/824 files\n",
      "[DONE] ../data_16k/noisy_testset_wav | Kept 689/824 files\n",
      "\n",
      "=== SUMMARY ===\n",
      "Total kept: 17740/24792 files\n",
      "\n",
      "['p226_114', 'p226_109', 'p226_059', 'p226_032', 'p226_088', 'p226_097', 'p226_117', 'p226_063', 'p226_025', 'p226_111', 'p226_086', 'p226_092', 'p226_090', 'p226_065', 'p226_068', 'p226_074']\n",
      "['p226_114', 'p226_109', 'p226_059', 'p226_032', 'p226_088', 'p226_097', 'p226_117', 'p226_063', 'p226_025', 'p226_111', 'p226_086', 'p226_092', 'p226_090', 'p226_065', 'p226_068', 'p226_074']\n"
     ]
    }
   ],
   "source": [
    "# Create Split\n",
    "# Extract the lists\n",
    "kept_files = build_kept_files_dict()\n",
    "noisy_train_files = kept_files[\"noisy_trainset_28spk_wav\"]\n",
    "clean_train_files = kept_files[\"clean_trainset_28spk_wav\"]\n",
    "noisy_test_files = kept_files[\"noisy_testset_wav\"]\n",
    "clean_test_files = kept_files[\"clean_testset_wav\"]\n",
    "\n",
    "# Create actual split\n",
    "train_loader, val_loader, test_loader = create_split(\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    sample_size=sample_size,  \n",
    "    noisy_train_files=noisy_train_files,\n",
    "    clean_train_files=clean_train_files,\n",
    "    noisy_test_files=noisy_test_files,\n",
    "    clean_test_files=clean_test_files,\n",
    "    ratio=0.9,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "test_run = next(iter(train_loader))\n",
    "print()\n",
    "print(test_run[2])\n",
    "print(test_run[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ca9e8",
   "metadata": {},
   "source": [
    "#### Training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51baf96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- TRAIN / VAL LOOP ----------\n",
    "def run_one_epoch(model, loader, criterion, optimizer=None):\n",
    "    \"\"\"\n",
    "    Run one epoch of training or validation.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        loader: DataLoader that yields (noisy, clean, filenames_x, filenames_y)\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer (None for eval mode)\n",
    "    \n",
    "    Returns:\n",
    "        avg_loss: Average loss over the epoch\n",
    "    \"\"\"\n",
    "    if optimizer is None:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for noisy, clean, _, _ in loader:\n",
    "        noisy = noisy.to(DEVICE)  # shape (B, 1, T)\n",
    "        clean = clean.to(DEVICE)  # shape (B, 1, T)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(noisy)\n",
    "\n",
    "        # Crop clean to match output length (in case of slight mismatch)\n",
    "        T = out.shape[-1]\n",
    "        clean_aligned = clean[..., :T]\n",
    "\n",
    "        loss = criterion(out, clean_aligned)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "        # Free intermediate tensors\n",
    "        del noisy, clean, clean_aligned, out, loss\n",
    "\n",
    "    avg_loss = total_loss / max(n_batches, 1)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=200,\n",
    "    print_every=10,\n",
    "    model_filename=\"best.pt\",\n",
    "    learning_rate=0.0001,\n",
    "    patience=20,\n",
    "    min_delta = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    Train model with early stopping.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        criterion: Loss function\n",
    "        train_loader: Training DataLoader\n",
    "        val_loader: Validation DataLoader\n",
    "        num_epochs: Max number of epochs\n",
    "        model_filename: Where to save best model\n",
    "        print_every: Print stats every N epochs\n",
    "    \n",
    "    Returns:\n",
    "        history: Dict with train_loss and val_loss lists\n",
    "    \"\"\"\n",
    "    model.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Train\n",
    "        train_loss = run_one_epoch(model, train_loader, criterion, optimizer)\n",
    "\n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "            val_loss = run_one_epoch(model, val_loader, criterion, optimizer=None)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        if epoch % print_every == 0 or epoch == num_epochs:\n",
    "            print(\n",
    "                f\"Epoch {epoch:03d} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f}\"\n",
    "            )\n",
    "\n",
    "        # Early stopping / best model tracking\n",
    "        if abs(val_loss - best_val) > min_delta:\n",
    "            best_val = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}.\")\n",
    "            break\n",
    "\n",
    "    # Save best model\n",
    "    model_path = MODEL_DIR / model_filename\n",
    "    if best_state is not None:\n",
    "        torch.save(best_state, model_path)\n",
    "        print(f\"Best model (val_loss={best_val:.4f}) saved to {model_path}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "# ---------- TEST EVAL ----------\n",
    "def evaluate_test(model, test_loader, criterion, model_filename=\"best.pt\"):\n",
    "    \"\"\"\n",
    "    Load best model from disk and evaluate on test set.\n",
    "    \n",
    "    Args:\n",
    "        model: Model class (will be instantiated)\n",
    "        test_loader: Test DataLoader\n",
    "        criterion: Loss function\n",
    "        model_filename: Path to saved model weights\n",
    "    \n",
    "    Returns:\n",
    "        test_loss: Average loss on test set\n",
    "    \"\"\"\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_loss = run_one_epoch(model, test_loader, criterion, optimizer=None)\n",
    "\n",
    "    print(f\"Test loss: {test_loss:.4f}\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "899e1806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA STUFF\n",
    "# ---------- MODEL ----------ç\n",
    "def load_model(model_filename, model):\n",
    "    model_path = MODEL_DIR / model_filename\n",
    "    state_dict = torch.load(model_path, map_location=DEVICE, weights_only=True)\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "# ---------- HISTORY ----------\n",
    "def save_history(history, filename):\n",
    "    hist_file = HIST_DIR / f\"{filename}.json\"\n",
    "    with open(hist_file, \"w\") as f:\n",
    "        json.dump(history, f)\n",
    "    print(f\"History saved to {hist_file}\")\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"val\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# ---------- EXTRA METRICS ----------\n",
    "class SNRLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, prediction, target):\n",
    "        noise = target - prediction\n",
    "        signal_power = torch.mean(target ** 2)\n",
    "        noise_power = torch.mean(noise ** 2) + self.eps\n",
    "\n",
    "        snr = 10 * torch.log10(signal_power / noise_power)\n",
    "        \n",
    "        # Because we minimize losses, return -SNR\n",
    "        return -snr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df056c",
   "metadata": {},
   "source": [
    "#### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a205396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(ModelClass, model_kwargs, Loss=Loss):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "    model = ModelClass(**model_kwargs)\n",
    "    loss = Loss()\n",
    "\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    filename = f'{ModelClass.__name__}_{Loss.__name__}'\n",
    "    print(f\"Training {ModelClass.__name__} ({n_params/1e6:.1f}M params) with {Loss.__name__}\")\n",
    "\n",
    "    start = time.time() # timer start\n",
    "    # Train the model\n",
    "    history = train(\n",
    "        model=model,\n",
    "        criterion=loss,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=num_epochs,\n",
    "        model_filename=filename,\n",
    "        learning_rate=LR,\n",
    "        patience=PATIENCE,\n",
    "        min_delta=min_delta,\n",
    "        print_every=print_every\n",
    "    )\n",
    "    print(f'Time elapsed: {time.time()-start:.2f}s')\n",
    "\n",
    "    # Save the history\n",
    "    save_history(history, filename)\n",
    "\n",
    "    # Face the fear, build the future\n",
    "    del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55af42d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Wave_UNet (10.3M params) with L1Loss\n",
      "Epoch 001 | train_loss=0.1470 | val_loss=0.1352\n",
      "Epoch 002 | train_loss=0.1280 | val_loss=0.1138\n",
      "Epoch 003 | train_loss=0.1045 | val_loss=0.0847\n",
      "Epoch 004 | train_loss=0.0702 | val_loss=0.0382\n",
      "Epoch 005 | train_loss=0.0410 | val_loss=0.0467\n",
      "Best model (val_loss=0.0467) saved to ../model/Wave_UNet_L1Loss\n",
      "Time elapsed: 6.41s\n",
      "History saved to ../history/Wave_UNet_L1Loss.json\n",
      "\n",
      "============================================================\n",
      "Training UNet (11.0M params) with L1Loss\n",
      "Epoch 001 | train_loss=0.0467 | val_loss=0.0527\n",
      "Epoch 002 | train_loss=0.0403 | val_loss=0.0540\n",
      "Epoch 003 | train_loss=0.0361 | val_loss=0.0548\n",
      "Epoch 004 | train_loss=0.0351 | val_loss=0.0554\n",
      "Epoch 005 | train_loss=0.0326 | val_loss=0.0544\n",
      "Best model (val_loss=0.0544) saved to ../model/UNet_L1Loss\n",
      "Time elapsed: 11.12s\n",
      "History saved to ../history/UNet_L1Loss.json\n",
      "\n",
      "============================================================\n",
      "Training UNet (11.0M params) with L1Loss\n",
      "Epoch 001 | train_loss=0.0310 | val_loss=0.0344\n",
      "Epoch 002 | train_loss=0.0273 | val_loss=0.0337\n",
      "Epoch 003 | train_loss=0.0246 | val_loss=0.0330\n",
      "Epoch 004 | train_loss=0.0238 | val_loss=0.0325\n",
      "Epoch 005 | train_loss=0.0220 | val_loss=0.0323\n",
      "Best model (val_loss=0.0323) saved to ../model/UNet_L1Loss\n",
      "Time elapsed: 5.14s\n",
      "History saved to ../history/UNet_L1Loss.json\n"
     ]
    }
   ],
   "source": [
    "# Wave-U-Net\n",
    "train_model(Wave_UNet, {})\n",
    "\n",
    "# # U-Net STFT\n",
    "LR = 1e-3\n",
    "PATIENCE = 10 \n",
    "\n",
    "fwd = STFTLogPower(n_fft=1024, hop_length=160, win_length=400)\n",
    "inv = ISTFTFromLogPower(n_fft=1024, hop_length=160, win_length=400)\n",
    "\n",
    "train_model(\n",
    "    UNet,\n",
    "    dict(encoder_channels=[32, 64, 128, 256, 256, 512, 512], # default\n",
    "        forward_transform=fwd,\n",
    "        inverse_transform=inv)\n",
    "    )\n",
    "\n",
    "\n",
    "fwd = MelLogMag(sample_rate=16000, n_fft=1024, hop_length=160, win_length=400, n_mels=128)\n",
    "inv = InvMelLogMag(sample_rate=16000, n_fft=1024, hop_length=160, win_length=400, n_mels=128)\n",
    "\n",
    "train_model(\n",
    "    UNet,\n",
    "    dict(forward_transform=fwd,\n",
    "        inverse_transform=inv),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d442d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('../history/Wave_UNet_L1Loss.json','r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "plt.plot(history[\"train_loss\"], label=\"loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-denoising",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
